{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home-2/jpopp4@jhu.edu/.local/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import RangeIndex\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as pl\n",
    "from matplotlib import rcParams\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.stats import rankdata\n",
    "import pickle\n",
    "import statistics as stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load each lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "endo = sc.read_h5ad(\"../data/endo.dpt.h5ad\")\n",
    "hep = sc.read_h5ad(\"../data/hep.dpt.h5ad\")\n",
    "neur = sc.read_h5ad(\"../data/neur.dpt.h5ad\")\n",
    "lineages = [endo, hep, neur]\n",
    "lineage_names = [\"endo\", \"hep\", \"neur\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[1, 2, 3],[4, 5, 6]])\n",
    "test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(sc_sub):\n",
    "    \"\"\"\n",
    "    input: sc_sub, a scanpy h5ad object, [cells x genes]\n",
    "    output: mat, a csr matrix, [1 x genes], summed over cells\n",
    "    \"\"\"\n",
    "    mat = csr_matrix.sum(sc_sub.X, 0)\n",
    "    return(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normalize(mat):\n",
    "    \"\"\"\n",
    "    input: mat, a csr matrix, [1 x genes], containing raw counts\n",
    "    output: logcpm, a csr matrix, [1 x genes], = ln(cpm + 1)\n",
    "    \"\"\"\n",
    "    cpm = mat * 1e6 / csr_matrix.sum(mat)\n",
    "    logcpm = cpm.log1p()\n",
    "    return(logcpm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(mat, center=True):\n",
    "    \"\"\"\n",
    "    input: mat, a [levels x gene] csr matrix\n",
    "           center, boolean indicating whether or not you want to center the data\n",
    "    output: scaled_mat, a [levels x gene] csr matrix where each gene has zero mean, unit variance across all levels\n",
    "    \"\"\"\n",
    "    if center:\n",
    "        mat = mat - np.mean(mat, 0)\n",
    "    stdevs = np.std(mat, 0)\n",
    "    stdevs[stdevs == 0] = 1\n",
    "    scaled_mat = mat / stdevs\n",
    "    return(scaled_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOC2L'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endo.var_names[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pseudobulk(sc_obj, stratifier=\"individual\", pt_label=\"dpt_pseudotime\", nbins=5):\n",
    "    \"\"\"\n",
    "    input: sc_obj, a full h5ad object\n",
    "           stratifier, the string identifier for the category over which pseudobulk will be aggregated (along with pseudotime)\n",
    "           pt_label, the string identifier for pseudotime, ie 'dpt_pseudotime'\n",
    "           nbins, the number of pseudotime bins to compute\n",
    "    output: Y, an [NGT, 1] array where N=number of levels to stratifier, G=num genes, T=nbins\n",
    "            X, an [NGT, 3] matrix (N,G,T as above), where the first column is time, second column is level, third is gene\n",
    "            leveldict, a dictionary mapping ints in second column of X to unique values in sc_obj.obs[stratifier]\n",
    "            genedict, a dictionary mapping ints in third column of X to gene names in sc_obj\n",
    "            cellcounts, \n",
    "    \"\"\"\n",
    "    levels = np.unique(sc_obj.obs[stratifier])\n",
    "    bin_width = 1/nbins\n",
    "    nL = len(levels)\n",
    "    nG = sc_obj.X.shape[1]\n",
    "    pseudobulk = np.zeros([nbins*nL, nG])\n",
    "    X = np.zeros([nbins*nL*nG, 3])\n",
    "    cellcounts = np.zeros(nbins*nL, dtype=int)\n",
    "    for t in range(nbins):\n",
    "        if t < nbins-1:\n",
    "            t_subset = (t*bin_width <= sc_obj.obs[pt_label]) & (sc_obj.obs[pt_label] < (t+1)*bin_width)\n",
    "        else:\n",
    "            t_subset = (t*bin_width <= sc_obj.obs[pt_label]) & (sc_obj.obs[pt_label] <= (t+1)*bin_width)\n",
    "        for l in range(nL):\n",
    "            l_subset = sc_obj.obs[stratifier] == levels[l]\n",
    "            sub = sc_obj[l_subset & t_subset]\n",
    "            # get cell counts for this subset\n",
    "            cellcounts[t*nL + l] = sub.X.shape[0]\n",
    "            # get metadata, store in X\n",
    "            t_sub = np.median(sub.obs[pt_label])\n",
    "            X[(t*nL*nG+l*nG):(t*nL*nG+(l+1)*nG),0] = t_sub\n",
    "            X[(t*nL*nG+l*nG):(t*nL*nG+(l+1)*nG),1] = l\n",
    "            X[(t*nL*nG+l*nG):(t*nL*nG+(l+1)*nG),2] = range(nG)\n",
    "            # get expression data, store in pseudobulk\n",
    "            sub_sum = aggregate(sub)\n",
    "            sub_cpm = log_normalize(sub)\n",
    "            pseudobulk[(len(levels) * nbins) + l, :] = sub_cpm\n",
    "    pseudobulk = scale(pseudobulk)\n",
    "    Y = pseudobulk.flatten()\n",
    "    leveldict = {i:levels[i] for i in range(nL)}\n",
    "    genedict = {i:sc_obj.var_names[i] for i in range(nG)}\n",
    "    return(Y, X, leveldict, genedict, cellcounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the parameters that hold across all lineages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "indivs = np.unique(endo.obs['individual'])\n",
    "batches = np.unique(endo.obs['Batch'])\n",
    "n_inds = 3\n",
    "n_batches = 3\n",
    "n_bins = 5\n",
    "_, nG = endo.X.shape\n",
    "nC_ind = n_inds * n_bins\n",
    "nC_batch = n_batches * n_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate pseudobulk and log normalize for each lineage, for each individual or batch, and for each diffusion pseudotime bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(len(lineages)):\n",
    "    lin = lineages[l]\n",
    "    lin_name = lineage_names[l]\n",
    "    counts = lin.X\n",
    "    t_ind = np.zeros(nC_ind)\n",
    "    t_batch = np.zeros(nC_batch)\n",
    "    ind = []\n",
    "    batch = []\n",
    "    numcells_ind = np.zeros(nC_ind)\n",
    "    numcells_batch = np.zeros(nC_batch)\n",
    "    Y_ind = np.zeros([nC_ind, nG])\n",
    "    Y_batch = np.zeros([nC_batch, nG])\n",
    "    bin_w = 1/n_bins\n",
    "    for t_bin in range(n_bins):\n",
    "        time_subset = (t_bin*bin_w <= lin.obs['dpt_pseudotime']) & (lin.obs['dpt_pseudotime'] < (t_bin+1)*bin_w)\n",
    "        for i in range(n_inds):\n",
    "            c = (n_inds * t_bin) + i\n",
    "            ind_subset = (lin.obs['individual'] == indivs[i])\n",
    "            lin_c = lin[time_subset & ind_subset]\n",
    "            # log normalize\n",
    "            exp_c = csr_matrix.sum(lin_c.X, 0)/csr_matrix.sum(lin_c.X)\n",
    "            exp_c = np.log(10**4 * exp_c + 1)\n",
    "            numcells_ind[c] = lin_c.shape[0]\n",
    "            Y_ind[int(c),:] = exp_c\n",
    "            t_ind[int(c)] = np.median(lin_c.obs['dpt_pseudotime'])\n",
    "            ind.append(indivs[i])\n",
    "        for b in range(n_batches):\n",
    "            c = (n_batches * t_bin) + b\n",
    "            batch_subset = (lin.obs['Batch'] == batches[b])\n",
    "            lin_c = lin[time_subset & batch_subset]\n",
    "            exp_c = csr_matrix.sum(lin_c.X, 0)/csr_matrix.sum(lin_c.X)\n",
    "            exp_c = np.log(10**4 * exp_c + 1)\n",
    "            numcells_batch[c] = lin_c.shape[0]\n",
    "            Y_batch[int(c),:] = exp_c\n",
    "            t_batch[int(c)] = np.median(endo_c.obs['dpt_pseudotime'])\n",
    "            batch.append(batches[b])\n",
    "    ind = np.array(ind)\n",
    "    batch = np.array(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
